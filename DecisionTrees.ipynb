{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Decision Trees\n",
    "\n",
    "## Machine Learning, Winter 2017\n",
    "\n",
    "### Name: [Jocelyn Shen, Nicholas Miklaucic, Kevin Sun, Darcy Meyer]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll perform the following tasks:\n",
    "1. Construct a (Python) class `DecisionTree` which will serve as our first machine learning model.\n",
    "2. Test it out on multiple datasets.  If you've done the above correctly, this shouldn't be hard!\n",
    "3. Determine the effects of overfitting and attempt some solutions, discussing which seem to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard import statements:\n",
    "from itertools import combinations, chain\n",
    "from statistics import mean, median\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DecisionTree` Class\n",
    "\n",
    "Construct a `DecisionTree` class in the cell below.  It should support the standard scikit-learn API: \n",
    "\n",
    "```\n",
    ">>> X, y = <your_dataset>\n",
    ">>> model = DecisionTree() # potentially with some parameters, if needed\n",
    ">>> model.fit(X,y)\n",
    ">>> model.predict(<new_sample_vector>)\n",
    "1\n",
    ">>> # If the model predicted your sample vector to be in class 1.\n",
    "```\n",
    "\n",
    "Note that your `predict` function should support either single predictions or multiple predictions, though you can force the user to do single predictions as a 2d array (single-row \"multiple\" predictions) so you only have one implementation to write.  What I mean by this is `model.predict(X)` should work (without error) to create all predictions for `y`.\n",
    "\n",
    "You should construct some human-readable visualization of your model, simply from a printout.  This way you can tell if the model is being built the way you want.  The best way to do this is to implement the `__str__` method for your class.  Probably the easiest way to do this is to iterate through the tree in a \"depth-first\" fashion, and for each node, just print out some basic facts, like the number of elements in that node, or the indices of those elements in `X`, and the class assignment if it's a leaf node; also, make sure the indentation level of each node increases as its depth increases.  It might be helpful to have your nodes be more than just the bare minimum object (which would probably be a list of the indices of the rows in `X` for the items in your node).  To reiterate: this should NOT be a \"beautiful\" printout with lines like:\n",
    "```\n",
    "            root\n",
    "           /    \\\n",
    "     child1      child2 \n",
    "    /      \\    /      \\\n",
    "...\n",
    "```\n",
    "\n",
    "Because that would get awkward fast.  What I'm imagining is:\n",
    "\n",
    "```\n",
    "root: <root_info>\n",
    "  child1: <child1_info>\n",
    "    grandchild1: <grandchild1_info>\n",
    "      ...\n",
    "    grandchild1: <grandchild2_info>\n",
    "      ...\n",
    "  child2: <child2_info>\n",
    "    grandchild1: <grandchild1_info>\n",
    "    grandchild1: <grandchild2_info>\n",
    "```\n",
    "\n",
    "By implementing this in `__str__` for your class, this will be the printout when you run:\n",
    "\n",
    "```\n",
    "model = DecisionTree(<whatever_you_need_to_do_to_create_your_model>)\n",
    "model.fit(X,y)\n",
    "print(model)\n",
    "```\n",
    "\n",
    "Recall the algorithm for fitting a decision tree:\n",
    "1. Start with all your data samples in a single node.\n",
    "2. For a given node, determine if you want to split at that node or not.  For now, this should just be a check to see if the node is \"pure\", meaning it only contains one class.  If you do decide to split it further, compute all possible splits of your data (all possible depth-1 subtrees).  For categorical variables, this should look like generating all pairs of combinations of classes.  For continuous or ordinal variables, sort the entries in that column, and then all possible splits involve cutting off at values between adjacent entries.  That is, if the entries in my continuous column are `[2.01, 3.425, 8.67, 493.6]`, then I have three splits, which are \n",
    "\"$x_i\\leq 2.01$\", \"$x_i\\leq 3.425$\", \"$x_i\\leq 8.67$\".\n",
    "3. Compute the change in Gini Impurity for each split, and choose the split that has the largest gain in information (most pure nodes).  Recall that the Gini Impurity for a node is \n",
    "$$ I = 1 - \\sum_{\\text{each class}} \\left(\\frac{\\text{# of elements in that class}}{\\text{# of elements in the node}}\\right)^2$$\n",
    "So then you want to maximize $I_\\text{new_child1} + I_\\text{new_child2} - I_\\text{old}$; that is, choose the split with the largest value for that quantity (roughly interpretted as \"information gain\", though for the record the term \"information gain\" is used in a totally-synonymous-but-technically-different situation).\n",
    "4. Repeat until all nodes are pure.\n",
    "5. (Get the above working first, and then later:) prune the tree back to avoid overfitting your training data. (See below)\n",
    "\n",
    "Note that your (Python) class should work for multi-class datasets (where you're trying to predict a `y` that has more than two classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This file implements a Node, a very simple class that simply has a left and a right child (both\n",
    "Nodes or None), and a value.\n",
    "\n",
    "Team: Jocelyn, Kevin, Nicholas\n",
    "Author: Nicholas\n",
    "\"\"\"\n",
    "\n",
    "from functools import total_ordering  # neat trick\n",
    "\n",
    "\n",
    "@total_ordering   # now every comparison function is defined. Neato!\n",
    "class Node:\n",
    "    \"\"\"A Node of a tree.\"\"\"\n",
    "\n",
    "    def __init__(self, val, left, right):\n",
    "        \"\"\"Represents a node of a binary tree.  Val is the value this Node has: can be anything but should\n",
    "        probably be hashable. Left and right are child Nodes, or None if this Node currently has no\n",
    "        child there.\"\"\"\n",
    "        self.val = val\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Gives the Node's value and the values of its children.\"\"\"\n",
    "        return self.str_with_offset(self)\n",
    "\n",
    "    @classmethod\n",
    "    def str_with_offset(cls, node, offset=0):\n",
    "        \"\"\"Generates a string printout of the node, but adds a given offset to every line for\n",
    "        alignment. If node is None, returns \"None\".\n",
    "        \"\"\"\n",
    "        if node is None:\n",
    "            return None\n",
    "        ans = []  # create list of lines and join at the end\n",
    "        ans.append(\"{}\".format(str(node.val)))\n",
    "        ans.append(\"\\n{}==> {} \".format(' ' * offset, cls.str_with_offset(node.left, offset+4)))\n",
    "        ans.append(\"\\n{}==> {} \".format(' ' * offset, cls.str_with_offset(node.right, offset+4)))\n",
    "        return ''.join(ans)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Gives the possible constructor.\"\"\"\n",
    "        return \"Node({}, {}, {})\".format(repr(self.val), repr(self.left), repr(self.right))\n",
    "\n",
    "    def children(self):\n",
    "        \"\"\"Returns a tuple (L, R) of children, if both exist, otherwise just the one that does, or (). Note\n",
    "        that this only returns a truthy value if the node has children: very useful!\n",
    "        \"\"\"\n",
    "        if self.left is None:\n",
    "            return () if self.right is None else (self.right,)\n",
    "        elif self.right is None:\n",
    "            return (self.left,)\n",
    "        else:\n",
    "            return (self.left, self.right)\n",
    "\n",
    "    def all_children(self):\n",
    "        \"\"\"Returns a tuple (L, R) of children, but includes None instead of removing it.\"\"\"\n",
    "        return (self.left, self.right)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"Uses the value, not the children, in comparison.\"\"\"\n",
    "        return self.val == other.val\n",
    "\n",
    "    def __le__(self, other):\n",
    "        \"\"\"Uses the value, not the children, in comparison.\"\"\"\n",
    "        return self.val <= other.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This is a class for encoding a split at a node of a decision tree in a class. That way, we can\n",
    "represent more than one kind of split as both a class method function that splits data, and as a\n",
    "logical condition in a human-readable format.\n",
    "\n",
    "Team: Jocelyn, Kevin, Nicholas\n",
    "Author: Nicholas\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Split:\n",
    "    \"\"\"Represents a decision tree split. For now, this is just a less-than-or-equal-to test with a\n",
    "    given value, but it could be extended in the future.\"\"\"\n",
    "\n",
    "    def __init__(self, predictor_name, val):\n",
    "        \"\"\"Val is the value that the split checks for <= relation to: for example, val=3.6 would make a\n",
    "        Split to test x <= 3.6 for some input x. Predictor_name is the name of the predictor to\n",
    "        test: for example, in a decision tree with a predictor y_1, you could use \"y_1\" as the\n",
    "        predictorname to check if y_1 <= 3.6.\n",
    "\n",
    "        \"\"\"\n",
    "        self.predictor_name = predictor_name\n",
    "        self.val = val\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"No explanation needed!\"\"\"\n",
    "        return \"{{{} <= {}}}\".format(str(self.predictor_name), str(self.val))\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Also no explanation needed.\"\"\"\n",
    "        return \"Split({}, {})\".format(repr(self.predictor_name), repr(self.val))\n",
    "\n",
    "    def split(self, x, predictor_matrix, use_iloc=False):\n",
    "        \"\"\"Predictor_matrix must be a DataFrame with the given predictor name in it. X is then the index row\n",
    "        to use for splitting, or, if use_iloc is True, the numerical index of a row (starting at\n",
    "        0). Returns the result of the split applied to that particular entry.\n",
    "        \"\"\"\n",
    "        if not hasattr(predictor_matrix[self.predictor_name], \"iloc\"):  # just a number\n",
    "            return predictor_matrix[self.predictor_name] <= self.val\n",
    "        \n",
    "        if use_iloc:\n",
    "            entry = predictor_matrix[self.predictor_name].iloc[x]\n",
    "        else:\n",
    "            entry = predictor_matrix[self.predictor_name][x]\n",
    "\n",
    "        return entry <= self.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This file provides a base Tree class for use with the DecisionTree class. It is simply a root\n",
    "node (which has children, which have children, etc.), with some useful functions for doing things\n",
    "you might want to do with a tree structure.\n",
    "\n",
    "Team: Jocelyn, Kevin, Nicholas\n",
    "Author: Nicholas\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    \"\"\"Represents a binary tree.\"\"\"\n",
    "    def __init__(self, root_node):\n",
    "        \"\"\"Takes in a root node with children, who have children, and so on.  Traverses the node to build\n",
    "        the tree, so make sure that you don't have an infinite loop!\n",
    "        \"\"\"\n",
    "        self.root = root_node\n",
    "        self.__calculate_node_list()\n",
    "\n",
    "    def __calculate_node_list(self):\n",
    "        \"\"\"Internal method for reconstructing the nodes list when a change happens.\"\"\"\n",
    "        self.nodes = [self.root]\n",
    "        children = self.root.children()\n",
    "        self.nodes += list(children)\n",
    "\n",
    "        while not all([c is None for c in children]):  # still values left\n",
    "            new_children = []\n",
    "            for child in children:\n",
    "                if child is None:\n",
    "                    new_children += [None, None]\n",
    "                else:\n",
    "                    new_children += list(child.all_children())\n",
    "            children = new_children\n",
    "            self.nodes += children\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Prints out a basic string representation.\"\"\"\n",
    "        return str(self.root)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Basic repr. Skips the recursive Node repr, as that could be EXTREMELY long.\"\"\"\n",
    "        return \"Tree({})\".format(repr(self.root.val))\n",
    "\n",
    "    def breadth_first_iterable(self):\n",
    "        \"\"\"Returns an iterator over the tree in breadth_first order. There might a a lot of None\n",
    "        values, because the entire tree is filled until the deepest node.\"\"\"\n",
    "        return iter(self.nodes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Trying to iterate over this class should return the nodes in breadth_first order. Lots of\n",
    "        Nones galore!\"\"\"\n",
    "        return iter(self.nodes)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.nodes[i]\n",
    "\n",
    "    def __depth_first_next(self, i):\n",
    "        \"\"\"Internal method for depth_first_iterable. Takes a 1-index to the nodes list and goes\n",
    "        through the following recursive step: if the node has children, return the left child's\n",
    "        result and the right child's result combined, with the current node at the beginning. If the\n",
    "        node is a leaf, return itself.\"\"\"\n",
    "        node = self.nodes[i-1]\n",
    "        l = self.__depth_first_next(i * 2) if node.left is not None else []\n",
    "        r = self.__depth_first_next(i * 2 + 1) if node.right is not None else []\n",
    "        return [i, *l, *r]\n",
    "\n",
    "    def depth_first_iterable(self):\n",
    "        \"\"\"Returns an iterator over the tree in depth_first order. For example, a complete 3-deep binary\n",
    "        tree numbered breadth-first 1, 2, 3, 4, 5, 6, 7 (1 -> 2 -> 4 is the left edge, for\n",
    "        clarity) would return an iterator over the nodes in the order 1, 2, 4, 5, 3, 6, 7.\n",
    "\n",
    "        \"\"\"\n",
    "        curr = 1   # \"walk\" down the tree using 1-indexed indices of the breadth-first children\n",
    "        depth_first_nodes = self.__depth_first_next(curr)\n",
    "        return [self.nodes[i - 1] for i in depth_first_nodes]  # subtract 1 to get the actual index\n",
    "\n",
    "    def set_child(self, position, direction, child):\n",
    "        \"\"\"Sets a child at a given point on the tree (using breadth-first indexing). Child is the Node to\n",
    "        add (or None to remove a child), position is the index of the parent, and direction is 0 for\n",
    "        left side or 1 for right side. Raises ValueError if you attempt to delete a parent.\n",
    "\n",
    "        As always, breadth-first indexing means 1-indexed as well.\n",
    "\n",
    "        \"\"\"\n",
    "        parent = self.nodes[position-1]\n",
    "        if child is None and parent.all_children()[direction] is not None:\n",
    "            # can't delete a parent!\n",
    "            raise ValueError(\"Can't delete a parent! Think of the children!\")\n",
    "        else:\n",
    "            if direction == 0:\n",
    "                parent.left = child\n",
    "            else:\n",
    "                parent.right = child\n",
    "        self.__calculate_node_list()\n",
    "\n",
    "    def index(self, node_val):\n",
    "        \"\"\"Gets the 1-indexed index of a given node value, the topmost furthest to the left if there\n",
    "        are multiple. Ignores the children. Returns None if nothing was found.\"\"\"\n",
    "        for i, node in enumerate(self.nodes):\n",
    "            if node.val == node_val:\n",
    "                return i + 1\n",
    "        return None\n",
    "\n",
    "    def search_all(self, node_val):\n",
    "        \"\"\"Returns a list of all node indexes (1-indexed breadth-first) that have the given node value,\n",
    "        ordered top-down and left-to-right.\n",
    "\n",
    "        \"\"\"\n",
    "        ans = []\n",
    "        for i, node in enumerate(self.nodes):\n",
    "            if node.val == node_val:\n",
    "                ans.append(i + 1)\n",
    "        return ans\n",
    "\n",
    "    def get_rows(self):\n",
    "        \"\"\"Gets a list of lists, where each list is the next-deepest row. Does not fill gaps with\n",
    "        None values.\"\"\"\n",
    "        rows = []\n",
    "        rows.append([self.root])\n",
    "        children = self.root.children()\n",
    "        while children:  # still values left\n",
    "            rows.append(list(children))\n",
    "            children = list(chain.from_iterable([child.children() for child in children]))\n",
    "        return rows\n",
    "\n",
    "    def get_row(self, row_depth):\n",
    "        \"\"\"Gets a list of all the nodes at a given height, where 0 is the root node. Does not fill\n",
    "        gaps with None values. Wraps get_rows\"\"\"\n",
    "        return self.get_rows()[row_depth]\n",
    "\n",
    "    def depth(self):\n",
    "        \"\"\"Returns the length of the longest walk down the tree.\"\"\"\n",
    "        return len(self.get_rows())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"This class creates a decision tree classifier for a given dataset.\"\"\"\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"Represents a decision tree classifier.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Creates a decision tree that can be fit to data.\"\"\"\n",
    "        self.tree = None\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Ignores DataFrames, only prints splits.\"\"\"\n",
    "        new_tree = deepcopy(self.tree)\n",
    "        for node in [n for n in list(new_tree) if n is not None]:\n",
    "            if len(node.val) == 1 or node.val[1] is None:\n",
    "                node.val = \"<data>\"\n",
    "            else:\n",
    "                node.val = str(node.val[1])\n",
    "        return str(new_tree)\n",
    "\n",
    "    @classmethod\n",
    "    def gini_vector(cls, col):\n",
    "        \"\"\"Given a single input Series with a single column filled with the digits 0-n, computes the\n",
    "    Gini impurity.\"\"\"\n",
    "        impurity = 0\n",
    "        n = len(set(col))\n",
    "        if n <= 1:  # sets without any elements or with a single class are pure by default\n",
    "            return 0\n",
    "\n",
    "        for i in range(n):\n",
    "            p_class = sum(col.map(lambda x: 1 if x == i else 0)) / len(col)\n",
    "            impurity += p_class ** 2\n",
    "\n",
    "        return 1 - impurity\n",
    "\n",
    "    @classmethod\n",
    "    def gini(cls, classes):\n",
    "        \"\"\"Computes the Gini impurity of the given data, a class vector or matrix in 0's and 1's or any\n",
    "    additional amount of classes.\n",
    "        \"\"\"\n",
    "        return classes.apply(cls.gini_vector).sum()\n",
    "\n",
    "    def gen_splits(self, data, classes):\n",
    "        \"\"\"Given input data and a corresponding matrix of classes, returns a list of Split objects\n",
    "        corresponding to all the possible splits of that dataset at that time.\"\"\"\n",
    "        splits = []\n",
    "        for predictor_name in data.columns:\n",
    "            pred = data[predictor_name]\n",
    "            # generate every possible split cutoff that would mean something\n",
    "            # also, remove duplicates\n",
    "            cutoffs = list(set(pred))\n",
    "            cutoffs = [c for c in cutoffs if c != max(cutoffs)]  # remove topmost element\n",
    "            splits += [Split(predictor_name, cutoff) for cutoff in cutoffs]\n",
    "        return splits\n",
    "\n",
    "    def execute_split(self, data, classes, split):\n",
    "        \"\"\"Given data with associated classes and split data, returns a tuple ((data_false, classes_false)\n",
    "        (data_true, classes_true)) with the entries that are false and the entries that satisfy the\n",
    "        split.\n",
    "        \"\"\"\n",
    "\n",
    "        # generate indices of cutoffs instead of just the data to preserve class data\n",
    "        good_indices = [i for i in range(data.shape[0]) if split.split(i, pd.DataFrame(data), True)]\n",
    "        bad_indices = [i for i in range(data.shape[0]) if i not in good_indices]\n",
    "\n",
    "        good = (data.iloc[good_indices, :], classes.iloc[good_indices, :])\n",
    "        bad = (data.iloc[bad_indices, :], classes.iloc[bad_indices, :])\n",
    "        return (bad, good)\n",
    "\n",
    "    def test_split(self, data, classes, split):\n",
    "        \"\"\"Given data with associated classes and a split, returns the sum of the Gini impurity of\n",
    "        the child nodes of this split if it is effected.\"\"\"\n",
    "\n",
    "        left, right = self.execute_split(data, classes, split)\n",
    "        return self.gini(left[1]) + self.gini(right[1])\n",
    "\n",
    "    def not_overfit(self, data, classes, split, k=0.05):\n",
    "        \"\"\"This method can be overridden or replaced to change how much the fitting algorithm prunes the\n",
    "        tree. The default is to require that at least a fraction of the input be separated (the\n",
    "        defaut is 5%).\"\"\"\n",
    "        left, right = self.execute_split(data, classes, split)\n",
    "        \n",
    "        return k <= left[0].shape[0] / data.shape[0] <= 1 - k\n",
    "\n",
    "    def create_split(self, pos, prune_func):\n",
    "        \"\"\"Given a position in the decision tree (1-based breadth-first indexing), first checks to see if\n",
    "        the data is pure. If it is, then it sets both children to None and stops. Otherwise, it\n",
    "        computes the split that minimizes the Gini impurity for each child node and executes it,\n",
    "        creating two new children that are the results of the split (left for false, right for\n",
    "        true).\n",
    "\n",
    "        Prune_func is the pruning function to determine whether a split is valid.\n",
    "        \"\"\"\n",
    "        # print(\"Creating split at position {}\".format(pos))\n",
    "\n",
    "        node = self.tree[pos-1]\n",
    "        node_val = node.val[0]  # the tuple (data, classes)\n",
    "        curr_gini = self.gini(node_val[1])\n",
    "\n",
    "        if curr_gini == 0:  # data is pure\n",
    "            self.tree.set_child(pos, 0, None)\n",
    "            self.tree.set_child(pos, 1, None)  # make this a leaf\n",
    "            return None  # we're done here!\n",
    "        else:  # generate possible splits\n",
    "            splits = self.gen_splits(*node_val)\n",
    "            splits = [split for split in splits if prune_func(*node_val, split)]\n",
    "            # print(splits)\n",
    "            if len(splits) == 0:  # no splits that separate into at least one class\n",
    "                self.tree.set_child(pos, 0, None)\n",
    "                self.tree.set_child(pos, 1, None)\n",
    "                return None\n",
    "            # find the best one\n",
    "            best = min(splits, key=lambda split: self.test_split(*node_val, split))\n",
    "            # print(sorted(splits, key=lambda split: self.test_split(*node_val, split))[:5])\n",
    "            if len(node.val) == 1:  # no split in the node yet\n",
    "                node.val.append(best)\n",
    "            else:  # overwrite a split\n",
    "                node.val[1].append(best)\n",
    "            # execute it\n",
    "            left, right = self.execute_split(*node_val, best)\n",
    "            # print(best)\n",
    "            # print(left[0].shape[0], right[0].shape[0])\n",
    "\n",
    "            self.tree.set_child(pos, 0, Node([left], None, None))\n",
    "            self.tree.set_child(pos, 1, Node([right], None, None))\n",
    "\n",
    "    def recursively_create_splits(self, pos, prune_func):\n",
    "        \"\"\"For the current Node, recursively splits all of its children (generating them as it goes) until\n",
    "        all of the leaves are pure, returning None. Prune_func is the function to reduce\n",
    "        overfitting.\n",
    "\n",
    "        \"\"\"\n",
    "        if pos > len(list(self.tree)) or self.tree[pos-1] is None:  # we stop here\n",
    "            return None\n",
    "        else:  # create two children and recurse to split them\n",
    "            self.create_split(pos, prune_func)\n",
    "            self.recursively_create_splits(pos * 2, prune_func)  # left child\n",
    "            self.recursively_create_splits(pos * 2 + 1, prune_func)  # right child\n",
    "            return None\n",
    "\n",
    "    def fit(self, X, y, pruning_func=None):\n",
    "        \"\"\"Fits a given input matrix to a given output vector using a decision tree. X should be a DataFrame\n",
    "        of numerical variables with any index or column names. y should be a vector or matrix with\n",
    "        the same height as X, as many columns as classes to predict, and each column should be a\n",
    "        list of 0's and 1's for a given class. The pruning_func parameter can be filled with any\n",
    "        function that takes in three arguments (data, classes, split) and returns True if that split\n",
    "        is allowed and False otherwise. The default, specified with None, is to only use splits that\n",
    "        separate 5% of the input.\n",
    "\n",
    "        \"\"\"\n",
    "        # start with just the entire dataset at the root, with no split\n",
    "        # I'm going to represent a single node of a tree as a value [(data, classes), split]\n",
    "        # where data and classes are \"what's left\" and split is the Split function that gives the\n",
    "        # left and right children, or None if the data is pure or the splits have stopped\n",
    "        if pruning_func is None:  # use default\n",
    "            pruner = self.not_overfit\n",
    "            \n",
    "        self.tree = Tree(Node([(X, y)], None, None))\n",
    "        self.recursively_create_splits(1, prune_func=pruner)  # pretty anticlimactic\n",
    "        return None\n",
    "\n",
    "    def __predict_vec(self, X):\n",
    "        \"\"\"Given an input vector with the required number of predictors, returns an output vector\n",
    "        y_hat representing the predicted classes for all of the classes it was fit to.\"\"\"\n",
    "\n",
    "        if self.tree is None:  # nothing to predict with!\n",
    "            raise ValueError(\"Must fit to a model before prediction!\")\n",
    "\n",
    "        curr_pos = 1\n",
    "        while True:  # loop until something is returned\n",
    "            curr_node = self.tree[curr_pos-1]\n",
    "            curr = curr_node.val\n",
    "            if len(curr) == 1 or curr[1] is None:  # no split, so must be pure or close\n",
    "                # return the mean of the classes, rounding to integers\n",
    "                # this way, even with non-pure pruned leaves you still get a result\n",
    "                if not hasattr(curr[0][1], \"__len__\"):  # single number\n",
    "                    return curr[0][1]  # we're done\n",
    "                else:  # lots of values\n",
    "                    if len(curr[0][1].shape) > 1:  # 2D array, so use array functions\n",
    "                        return curr[0][1].mean().round()\n",
    "                    else:  # just get the mean and use basic round, not a method\n",
    "                        return int(curr[0][1].mean())\n",
    "            else:  # go down to the correct child and try again\n",
    "                if curr[1].split(0, X, use_iloc=True):  # split with the input data\n",
    "\n",
    "                    curr_pos = curr_pos * 2 + 1  # right child\n",
    "\n",
    "                else:  # left child, because the Split returned False\n",
    "                    curr_pos *= 2\n",
    "\n",
    "            # now, just repeat until we get to a leaf!\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"For every row in X, predicts the classes and returns a matrix Y representing the\n",
    "        predicted classes.\"\"\"\n",
    "        if len(X.shape) == 1:  # single row\n",
    "            return self.__predict_vec(X)\n",
    "\n",
    "        return X.apply(self.__predict_vec, axis=1)\n",
    "\n",
    "    def __score_col(self, col1, col2):\n",
    "        \"\"\"Returns the accuracy score for two Series.\"\"\"\n",
    "        correct = 0\n",
    "        for i in range(len(col1)):\n",
    "            if col1.iloc[i] == col2.iloc[i]:\n",
    "                correct += 1\n",
    "        return correct / len(col1)\n",
    "\n",
    "    def score(self, X, true_y):\n",
    "        \"\"\"Gets the accuracy score of the classifier given the X as input and with true_y as the\n",
    "        actual values. If there are multiple classes, returns an iterable of each accuracy score.\"\"\"\n",
    "\n",
    "        preds = self.predict(X)\n",
    "        if len(preds.shape) >= 2 and preds.shape[1] > 1:  # multiple classes\n",
    "            scores = []\n",
    "            for colname in preds:\n",
    "                scores.append(self.__score_col(preds[colname], true_y[colname]))\n",
    "            return scores\n",
    "        else:  # just one class\n",
    "            if isinstance(preds, pd.DataFrame):  # convert to Series\n",
    "                converted_pred = preds.iloc[:, 0]\n",
    "            else:\n",
    "                converted_pred = preds\n",
    "\n",
    "            if isinstance(true_y, pd.DataFrame):  # convert to Series\n",
    "                converted_true = true_y.iloc[:, 0]\n",
    "            else:\n",
    "                converted_true = true_y\n",
    "\n",
    "            return self.__score_col(converted_pred, converted_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out your code, here's a simple dataset.  You could check it by hand if you need to debug.  You're trying to predict whether an animal is a mammal or not (the class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = [[\"human\", \"warm-blooded\", \"yes\", \"no\", \"no\", \"yes\"],\n",
    "       [\"pigeon\", \"warm-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "       [\"elephant\", \"warm-blooded\", \"yes\", \"yes\", \"no\", \"yes\"],\n",
    "       [\"leopard shark\", \"cold-blooded\", \"yes\", \"no\", \"no\", \"no\"],\n",
    "       [\"turtle\", \"cold-blooded\", \"no\", \"yes\", \"no\", \"no\"],\n",
    "       [\"penguin\", \"cold-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "       [\"eel\", \"cold-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "       [\"dolphin\", \"warm-blooded\", \"yes\", \"no\", \"no\", \"yes\"],\n",
    "       [\"spiny anteater\", \"warm-blooded\", \"no\", \"yes\", \"yes\", \"yes\"],\n",
    "       [\"gila monster\", \"cold-blooded\", \"no\", \"yes\", \"yes\", \"no\"]]\n",
    "\n",
    "df = pd.DataFrame(mat, columns=[\"Name\",\n",
    "                                \"Body Temperature\",\n",
    "                                \"Gives Birth\",\n",
    "                                \"Four-legged\",\n",
    "                                \"Hibernates\",\n",
    "                                \"Class Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score, Confusion Matrix, Precision, and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some classification metrics to your models, like the `accuracy_score` and `confusion_matrix`.  Add additionally [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall), and explain what those are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_real is an array of the real values of the testing data\n",
    "# test_results is an array of predictions from the testing data\n",
    "def accuracy_score(test_real, test_results):\n",
    "    count = 0\n",
    "    for i in range(len(test_real)):\n",
    "        if test_real[i] == test_results[i]:\n",
    "            count +=1\n",
    "    return float(count)/len(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(test_real,test_results):\n",
    "    true_n = 0\n",
    "    true_p = 0\n",
    "    false_n = 0\n",
    "    false_p = 0\n",
    "    for i in range(len(test_real)):\n",
    "        p = test_results[i]\n",
    "        r = test_real[i]\n",
    "        if  p == 0 and r == 0:\n",
    "            true_n += 1\n",
    "        elif p == 0 and r == 1:\n",
    "            false_n += 1\n",
    "        elif p == 1 and r == 0:\n",
    "            false_p += 1\n",
    "        elif p == 1 and r == 1:\n",
    "            true_p += 1\n",
    "    return np.matrix([[true_p,false_p],[false_n,true_n]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is the fraction of elements that are relevant (for example if 5 chess pieces in a board of 10 pieces are identified as black, but only 3 of them are actually black, then the precision is 3/5)\n",
    "Recall is the fraction of relevant instances that are retrieved (in this example, 5/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def precision(test_real, test_results):\n",
    "    true_n = 0\n",
    "    true_p = 0\n",
    "    false_n = 0\n",
    "    false_p = 0\n",
    "    for i in range(len(test_real)):\n",
    "        p = test_results[i]\n",
    "        r = test_real[i]\n",
    "        if  p == 0 and r == 0:\n",
    "            true_n += 1\n",
    "        elif p == 0 and r == 1:\n",
    "            false_n += 1\n",
    "        elif p == 1 and r == 0:\n",
    "            false_p += 1\n",
    "        elif p == 1 and r == 1:\n",
    "            true_p += 1\n",
    "    return float(true_p)/(true_p + false_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recall(test_real, test_results):\n",
    "    true_n = 0\n",
    "    true_p = 0\n",
    "    false_n = 0\n",
    "    false_p = 0\n",
    "    for i in range(len(test_real)):\n",
    "        p = test_results[i]\n",
    "        r = test_real[i]\n",
    "        if  p == 0 and r == 0:\n",
    "            true_n += 1\n",
    "        elif p == 0 and r == 1:\n",
    "            false_n += 1\n",
    "        elif p == 1 and r == 0:\n",
    "            false_p += 1\n",
    "        elif p == 1 and r == 1:\n",
    "            true_p += 1\n",
    "    return float(true_p)/(true_p + false_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out on multiple datasets\n",
    "\n",
    "Feel free to split these amongst your group mates, then consolodate it into one notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mammals Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The dataset `X` above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a\n",
      "==> b\n",
      "    ==> None \n",
      "    ==> c\n",
      "        ==> None \n",
      "        ==> d\n",
      "            ==> None \n",
      "            ==> None    \n",
      "==> e\n",
      "    ==> None \n",
      "    ==> None  \n",
      "\n",
      "a\n",
      "==> b\n",
      "    ==> None \n",
      "    ==> c\n",
      "        ==> f\n",
      "            ==> None \n",
      "            ==> None  \n",
      "        ==> d\n",
      "            ==> None \n",
      "            ==> None    \n",
      "==> e\n",
      "    ==> None \n",
      "    ==> None  \n",
      "Class Label    1.0\n",
      "dtype: float64\n",
      "Class Label    0.0\n",
      "dtype: float64\n",
      "Class Label    1.0\n",
      "dtype: float64\n",
      "Class Label    0.0\n",
      "dtype: float64\n",
      "Class Label    0.0\n",
      "dtype: float64\n",
      "Class Label    0.0\n",
      "dtype: float64\n",
      "Class Label    0.0\n",
      "dtype: float64\n",
      "Class Label    1.0\n",
      "dtype: float64\n",
      "Class Label    1.0\n",
      "dtype: float64\n",
      "Class Label    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, [\"Body Temperature\", \"Gives Birth\", \"Four-legged\", \"Hibernates\"]]\n",
    "y = df.loc[:, \"Class Label\"]\n",
    "\n",
    "X[\"Body Temperature\"] = X[\"Body Temperature\"].apply(lambda x: 1 if x == \"warm-blooded\" else 0)\n",
    "for col in X.columns[1:]:\n",
    "    X[col] = X[col].apply(lambda x: 1 if x == \"yes\" else 0)\n",
    "\n",
    "y = pd.DataFrame(y.apply(lambda x: 1 if x == \"yes\" else 0))\n",
    "\n",
    "\n",
    "tree = Tree(Node('a',\n",
    "                 Node('b', None,\n",
    "                      Node('c', None,\n",
    "                           Node('d', None, None))),\n",
    "                 Node('e', None, None)))\n",
    "\n",
    "\n",
    "def print_tree(t):\n",
    "    print('\\n'.join([repr(x) for x in list(t)]))\n",
    "\n",
    "print()\n",
    "print(tree)\n",
    "tree.set_child(5, 0, Node('f', None, None))\n",
    "print()\n",
    "print(tree)\n",
    "\n",
    "\n",
    "\n",
    "dt = DecisionTree()\n",
    "dt.fit(X, y)\n",
    "pred = []\n",
    "for i in range(len(df)):\n",
    "    x_pred = X.iloc[i]\n",
    "    pred.append(dt.predict(x_pred)['Class Label'])\n",
    "    print(dt.predict(x_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_r = [val[0] for val in y.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4, 0],\n",
       "        [0, 6]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(test_r,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) To double check that your multi-class support is working, use the [iris dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris).  Plot some decision boundaries of the classifier you make in all the pairs of dimensions in your scatter plots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width  class\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0\n",
       "2           4.7          3.2           1.3          0.2      0\n",
       "3           4.6          3.1           1.5          0.2      0\n",
       "4           5.0          3.6           1.4          0.2      0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris.data', names = [\"sepal-length\", \"sepal-width\", \"petal-length\", \"petal-width\", \"class\"])\n",
    "iris_types = np.unique(df['class'])\n",
    "df['class'] = df['class'].map({iris_types[0]:0,iris_types[1]:1,iris_types[2]:2})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8833333333333333\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "X = df[['sepal-length','sepal-width','petal-length','petal-width']]\n",
    "y = df['class']\n",
    "\n",
    "iris_x_train, iris_x_test, iris_y_train, iris_y_test = train_test_split(X.values, y.values, test_size=0.4)\n",
    "\n",
    "iris_x_train = pd.DataFrame(iris_x_train, columns=X.columns)\n",
    "iris_x_test = pd.DataFrame(iris_x_test, columns=X.columns)\n",
    "\n",
    "iris_y_train = pd.DataFrame({'type': iris_y_train})\n",
    "iris_y_test = pd.DataFrame({'type': iris_y_test})\n",
    "\n",
    "dt = DecisionTree()\n",
    "dt.fit(iris_x_train, iris_y_train)\n",
    "y_bar = dt.predict(iris_x_test)\n",
    "print(dt.score(iris_x_test, iris_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.           0.51666667]\n",
      " [  6.           0.91666667]\n",
      " [ 11.           0.91666667]\n",
      " [ 16.           0.91666667]\n",
      " [ 21.           0.91666667]\n",
      " [ 26.           0.91666667]]\n"
     ]
    }
   ],
   "source": [
    "acc_scores = []\n",
    "for num_nodes in range(1, 31, 5):\n",
    "    fixed_dt = FixedNodesDecisionTree(num_nodes)\n",
    "    fixed_dt.fit(iris_x_train, iris_y_train)\n",
    "    acc_scores.append((num_nodes, fixed_dt.score(iris_x_test, iris_y_test)))\n",
    "\n",
    "acc_scores = np.array(acc_scores)\n",
    "print(acc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_ = (acc_scores[:,0])\n",
    "y_ = (acc_scores[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x159a5167d68>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAECCAYAAAAFL5eMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x159a5f92438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_r = [x[0] for x in iris_y_test.values]\n",
    "pred = [x[0] for x in y_bar.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833333333333333"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[14,  1],\n",
       "        [ 1, 16]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_col = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is modified from http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEjCAYAAADUjb3BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFjHtkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x159a5e41860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "n_classes = 3\n",
    "plot_colors = \"bry\"\n",
    "plot_step = 0.02\n",
    "\n",
    "\n",
    "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
    "                                [1, 2], [1, 3], [2, 3]]):\n",
    "    # We only take the two corresponding features\n",
    "    \n",
    "    X1 = X.values[:, pair]\n",
    "    y1 = y.values\n",
    "\n",
    "    # Train\n",
    "    clf = DecisionTreeClassifier().fit(X1, y1)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "    x_min, x_max = X1[:, 0].min() - 1, X1[:, 0].max() + 1\n",
    "    y_min, y_max = X1[:, 1].min() - 1, X1[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.xlabel(x_col[pair[0]])\n",
    "\n",
    "    plt.ylabel(x_col[pair[1]])\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X1[idx, 0], X1[idx, 1], c=color, label=y.unique()[i],\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "    #plt.axis(\"tight\")\n",
    "\n",
    "plt.suptitle(\"Decision surface of a decision tree using paired features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Take a look at some of the [dataset constructors in scikit-learn](http://scikit-learn.org/stable/datasets/#sample-generators).  Pick one that will allow you to generate a dataset that has $\\geq 4$ features, and multiple classes ($\\geq 3$); but also make sure that when I run your code with some tweaked numbers from these, it will still work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4  class\n",
       "0   8.0  19.0  10.0   5.0  12.0      1\n",
       "1   9.0   6.0  14.0   3.0  13.0      2\n",
       "2   7.0  11.0  10.0   7.0  19.0      3\n",
       "3  11.0  20.0   9.0  11.0  18.0      1\n",
       "4  14.0  12.0   8.0  12.0  10.0      3"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "n_f = 5\n",
    "n_c = 3\n",
    "X,Y = make_multilabel_classification(n_samples=50, n_features=n_f, n_classes=n_c)\n",
    "Y = np.sum(Y, axis=1)\n",
    "Y = pd.DataFrame(Y, columns = ['class'])\n",
    "df = pd.concat([pd.DataFrame(X),Y], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_col_names = [(n) for n in range(n_f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "\n",
    "X = df[x_col_names]\n",
    "y = df['class']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.4)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns=X.columns)\n",
    "x_test = pd.DataFrame(x_test, columns=X.columns)\n",
    "\n",
    "y_train = pd.DataFrame({'type': y_train})\n",
    "y_test = pd.DataFrame({'type': y_test})\n",
    "\n",
    "dt = DecisionTree()\n",
    "dt.fit(x_train, y_train)\n",
    "y_bar = dt.predict(x_test)\n",
    "print(dt.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_r = [x[0] for x in y_test.values]\n",
    "pred = [x[0] for x in y_bar.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5, 0],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(test_r,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Kaggle is a website which offers machine learning challenges to anyone with an interest in working on them, some of which have real prizes associated with them.  The [Titanic challenge](https://www.kaggle.com/c/titanic/data) is a tutorial challenge which has you attempting to predict whether someone did or did not die on board the Titanic, based on their criteria.  In order to download the dataset, you'll need to make an account, and agree to some scary-sounding agreement about not sharing their data with the world (to make their legal team happy).  Do only the minimum of data cleanup on it, trash the name column (unless you want to get really fancy), and fit a decision tree to the dataset.  Make sure to save some data for testing purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.drop('Name', 1)\n",
    "df.Sex = df.Sex.map({'male':0, 'female': 1})\n",
    "df.Embarked = df.Embarked.map({'S':0,'C':1})\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch    Ticket     Fare  \\\n",
       "1             2         1       1    1  38.0      1      0  PC 17599  71.2833   \n",
       "3             4         1       1    1  35.0      1      0    113803  53.1000   \n",
       "6             7         0       1    0  54.0      0      0     17463  51.8625   \n",
       "10           11         1       3    1   4.0      1      1   PP 9549  16.7000   \n",
       "11           12         1       1    1  58.0      0      0    113783  26.5500   \n",
       "\n",
       "   Cabin  Embarked  \n",
       "1    C85       1.0  \n",
       "3   C123       0.0  \n",
       "6    E46       0.0  \n",
       "10    G6       0.0  \n",
       "11  C103       0.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTree()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.4)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns=X.columns)\n",
    "x_test = pd.DataFrame(x_test, columns=X.columns)\n",
    "\n",
    "y_train = pd.DataFrame({'type': y_train})\n",
    "y_test = pd.DataFrame({'type': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTree()\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7671232876712328\n"
     ]
    }
   ],
   "source": [
    "y_bar = dt.predict(x_test)\n",
    "print(dt.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) For the dataset `noisy_dataset.csv`, available on Canvas in `Files`, put the data into `test` and `train` sets, and then construct a family of decision trees with an increasing number of nodes, say from 3 up to something large (large enough that the test accuracy starts getting awful). Plot a pair of curves on the same axes: (# of nodes) vs. model accuracy (training and test).  Discuss which models make the best predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.169124</td>\n",
       "      <td>6.545124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.244786</td>\n",
       "      <td>7.681310</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926550</td>\n",
       "      <td>5.063571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.298943</td>\n",
       "      <td>7.374926</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.479117</td>\n",
       "      <td>8.684585</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       x_1       x_2    y\n",
       "0           0  0.169124  6.545124  0.0\n",
       "1           1  1.244786  7.681310  0.0\n",
       "2           2  0.926550  5.063571  0.0\n",
       "3           3  6.298943  7.374926  0.0\n",
       "4           4  4.479117  8.684585  0.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"noisy_dataset.csv\")\n",
    "X = df[['x_1', 'x_2']]\n",
    "y = df['y']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: runtime extremely long on this one, so it didn't finish running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-b844fe80cedf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0my_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, pruning_func)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pretty anticlimactic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mrecursively_create_splits\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# create two children and recurse to split them\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# left child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursively_create_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_func\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# right child\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2c484a48b40e>\u001b[0m in \u001b[0;36mcreate_split\u001b[1;34m(self, pos, prune_func)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcurr_gini\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# data is pure\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_child\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_child\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# make this a leaf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# we're done here!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-cfa8a946b7db>\u001b[0m in \u001b[0;36mset_child\u001b[1;34m(self, position, direction, child)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__calculate_node_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-cfa8a946b7db>\u001b[0m in \u001b[0;36m__calculate_node_list\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                     \u001b[0mnew_children\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                     \u001b[0mnew_children\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.4)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns=X.columns)\n",
    "x_test = pd.DataFrame(x_test, columns=X.columns)\n",
    "\n",
    "y_train = pd.DataFrame({'type': y_train})\n",
    "y_test = pd.DataFrame({'type': y_test})\n",
    "\n",
    "dt = DecisionTree()\n",
    "dt.fit(x_train, y_train)\n",
    "y_bar = dt.predict(x_test)\n",
    "print(dt.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_r = [x[0] for x in y_test.values]\n",
    "pred = [x[0] for x in y_bar.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall(test_r,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FixedNodesDecisionTree(DecisionTree):\n",
    "    \"\"\"A decision tree with a fixed amount of splits.\"\"\"\n",
    "    def __init__(self, num_nodes):\n",
    "        \"\"\"Num_nodes is the number of nodes allowed.\"\"\"\n",
    "        self.num_nodes = num_nodes\n",
    "        self.curr_nodes = 0  # no nodes currently\n",
    "        super().__init__()\n",
    "\n",
    "    def not_overfit(self, data, classes, split):\n",
    "        \"\"\"Does the parent's not_overfit and also checks if the global amount of nodes has increased\n",
    "        too far, in which case it returns False.\"\"\"\n",
    "        return self.curr_nodes < self.num_nodes\n",
    "\n",
    "    def create_split(self, pos, prune_func):\n",
    "        \"\"\"Does the super's version, and then increments curr_nodes.\"\"\"\n",
    "        node = self.tree[pos-1]\n",
    "        node_val = node.val[0]  # the tuple (data, classes)\n",
    "        curr_gini = self.gini(node_val[1])\n",
    "\n",
    "        if curr_gini == 0:  # data is pure\n",
    "            self.tree.set_child(pos, 0, None)\n",
    "            self.tree.set_child(pos, 1, None)  # make this a leaf\n",
    "            return None  # we're done here!\n",
    "        else:  # generate possible splits\n",
    "            splits = self.gen_splits(*node_val)\n",
    "            splits = [split for split in splits if prune_func(*node_val, split)]\n",
    "            # print(splits)\n",
    "            if len(splits) == 0:  # no splits that separate into at least one class\n",
    "                self.tree.set_child(pos, 0, None)\n",
    "                self.tree.set_child(pos, 1, None)\n",
    "                return None\n",
    "            # find the best one\n",
    "            best = min(splits, key=lambda split: self.test_split(*node_val, split))\n",
    "            # print(sorted(splits, key=lambda split: self.test_split(*node_val, split))[:5])\n",
    "            if len(node.val) == 1:  # no split in the node yet\n",
    "                node.val.append(best)\n",
    "            else:  # overwrite a split\n",
    "                node.val[1].append(best)\n",
    "            # execute it\n",
    "            left, right = self.execute_split(*node_val, best)\n",
    "\n",
    "            # ONLY CHANGED PART\n",
    "            # just increment the number of nodes\n",
    "            self.curr_nodes += 1\n",
    "\n",
    "            # print(best)\n",
    "            # print(left[0].shape[0], right[0].shape[0])\n",
    "\n",
    "            self.tree.set_child(pos, 0, Node([left], None, None))\n",
    "            self.tree.set_child(pos, 1, Node([right], None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To use the fixed nodes class:\n",
    "acc_scores = []\n",
    "for num_nodes in range(1, 31, 5):\n",
    "    fixed_dt = FixedNodesDecisionTree(num_nodes)\n",
    "    fixed_dt.fit(x_train, y_train)\n",
    "    acc_scores.append((num_nodes, fixed_dt.score(x_test, y_test)))\n",
    "\n",
    "acc_scores = np.array(acc_scores)\n",
    "print(acc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the nodes versus the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ = (acc_scores[:,0])\n",
    "y_ = (acc_scores[:,1])\n",
    "plt.scatter(x_,y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to scikit-learn's `DecisionTreeClassifier` class\n",
    "\n",
    "It should come as no surprise to you that scikit-learn has a [decision tree class](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier).  Compare your constructed class to theirs in terms of their functionality, what attributes and constructor-arguments does their decision tree class have that yours does not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DecisionTreeClassifier class from sci-kit learn comes with a multitude constructor arguments and attributes that our DecisionTree class does not have. The methods we had were pretty similar to their methods, for example \"fit\" to build the decision tree classifier from the training set (X, y) and \"predict\" to predict the class for the X inputs.\n",
    "\n",
    "### Sci-kit Constructor parameters\n",
    "    \n",
    "criterion=\"string\", where \"string\" default is \"gini\"\n",
    "This argument measures the quality of a split, including gini for the Gini impurity and entropy for the information gain.\n",
    "\n",
    "splitter : string, optional (default=best)\n",
    "The strategy used to choose the split at each node, for example, best to choose the best split and random to choose the best random split.\n",
    "\n",
    "max_features : int, float, string or None, optional (default=None)\n",
    "The number of features to consider when looking for the best split.\n",
    "\n",
    "max_depth : int or None, optional (default=None)\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "min_samples_split : int, float, optional (default=2)\n",
    "The minimum number of samples required to split an internal node.\n",
    "\n",
    "min_samples_leaf : int, float, optional (default=1)\n",
    "The minimum number of samples required to be at a leaf node.\n",
    "\n",
    "min_weight_fraction_leaf : float, optional (default=0.)\n",
    "The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node.\n",
    "\n",
    "max_leaf_nodes : int or None, optional (default=None)\n",
    "Thie argument is used to grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined based on lowest impurity.\n",
    "\n",
    "class_weight : dict, list of dicts, balanced or None, optional (default=None)\n",
    "This argument represents weights associated with classes in the form {class_label: weight}.\n",
    "\n",
    "random_state : int, RandomState instance or None, optional (default=None)\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "min_impurity_split : float, optional (default=1e-7)\n",
    "Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
    "\n",
    "### Sci-kit Attributes\n",
    "\n",
    "classes_ : array of shape = [n_classes] or a list of such arrays\n",
    "Single output problems: The classes labels.\n",
    "Multi-output problems: A list of arrays of class labels\n",
    "\n",
    "feature_importances_ : array of shape = [n_features]\n",
    "\"The feature importances. The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance [R245].\"\n",
    "\n",
    "max_features_ : int,\n",
    "The inferred value of max_features.\n",
    "\n",
    "n_classes_ : int or list\n",
    "Single output problems: The number of classes,\n",
    "Multi-output problems: A list containing the number of classes for each output.\n",
    "\n",
    "n_features_ : int\n",
    "Number of features when fit is performed.\n",
    "\n",
    "n_outputs_ : int\n",
    "Number of outputs when fit is performed.\n",
    "\n",
    "tree_ : Tree object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and what to do about it\n",
    "\n",
    "What we saw (hopefully!) in dataset 6 above is called __overfitting__, meaning our model is learning the noise in the training data.  This weakens the models predictive power.  There are many options to reduce overfitting, here are a few.  Implement at least one of them, until you have something that makes your models noticeably better.\n",
    "\n",
    "* Add a stopping condition: \n",
    " * stop splitting off more nodes when a node reaches either a minimal number of items per node _or_ is a pure node,\n",
    " * stop splitting by not allowing any child nodes to go below a minimum number of nodes,\n",
    " * stop splitting when you've reached some maximum depth.\n",
    "* After fitting a deep, overfit tree, use a __validation__ set to _prune_ the tree: remove nodes by rejoining children into parents, then test them against the validation set to see if the pruned tree was better.  Do this until you stop seeing improvements on the validation set.  Here a validation set means a third split of data, different from test and train.  It's different from the training set because you're not training the model on it, but it's also not testing data because you're changing your model based on knowledge gained from the dataset.  It's somewhere in between.  Feel free to ask me about _cross-validation_ as well, and how you could use that instead.  We'll talk about it eventually, but I don't want to add more to this project than is already here.\n",
    "\n",
    "__Explain to me what you did, and where it shows up in your code (for example, is it in your class definition?).__\n",
    "\n",
    "We added a stopping method in the decision tree class. It is in the method, not_overfit. The default is to require that at least a fraction of the input be separated (the defaut is 5%)\n",
    "left, right = self.execute_split(data, classes, split)\n",
    "return k <= left[0].shape[0] / data.shape[0] <= 1 - k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible extensions\n",
    "\n",
    "Here are two extensions of the `DecisionTree` class that you made.  They are entirely optional, so don't feel you need to do them!\n",
    "\n",
    "* In reality, people use decision trees on a limited basis, typically only when model interpretability is forced by government institutions (so, this happens a lot with banks, for example).  What you normally do is build a __forest__ of trees, that is, a collection of several trees (a common number is 50-500 trees), and then have them vote.  However, if you let your trees build themselves from the same exact datasets each time, they will be roughly the same, and the power of this voting model will be irrelevant.  Thus, one extremely common model is called the __Random Forest__ classifier: give each tree only a subset of the features to train from, don't prune at all (allow them to overfit on that subset), and then have them vote.  This increases the variance of the distribution of tree votes, which helps to average out the errors.  Create a new Python class that builds this classification model.  Note that Random Forests are a current industry favorite (among other things, like support vector machines, boosted trees, and neural networks), meaning if you do this you'll have created a model capable of hacking it with some of the best!\n",
    "\n",
    "* Scikit-learn's `DecisionTreeClassifier` has a somewhat pretty visualization of the tree that can be exported using the library `GraphViz`.  There are python wrappers to this module, the most common is `pydot`.  Using these libraries, or similar ones, add the functionality of constructing an attractive visualization of your decision tree class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This file implements a subclass of DecisionTree that has one small caveat: when it makes a split,\n",
    "it chooses a random subset of the features it has to make a split with, thereby reducing the tree's\n",
    "tendency to be dominated by a few strong predictors.\n",
    "Team: Jocelyn, Kevin, Nicholas\n",
    "Author: Nicholas\n",
    "\"\"\"\n",
    "\n",
    "from random import sample\n",
    "\n",
    "\n",
    "class RandomDecisionTree(DecisionTree):\n",
    "    \"\"\"A random forest decision learner.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes a RandomDecisionTree ready for fitting.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def gen_splits(self, data, classes):\n",
    "        \"\"\"Generates all possible splits using only the square root of the number of available\n",
    "        features.\"\"\"\n",
    "        splits = []\n",
    "        for predictor_name in sample(data.columns, int(len(data.columns) ** (0.5))):\n",
    "            pred = data[predictor_name]\n",
    "            # generate every possible split cutoff that would mean something\n",
    "            cutoffs = list(pred)\n",
    "            cutoffs = [c for c in cutoffs if c != max(cutoffs)]  # remove topmost element\n",
    "            splits += [Split(predictor_name, cutoff) for cutoff in cutoffs]\n",
    "        return splits\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Does no pruning, just the custom feature bagging. Fits the tree to predict the classes in\n",
    "        y given the features in X.\"\"\"\n",
    "        super().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"This file uses a random forest, a bunch of individual unpruned decision trees with access to only\n",
    "some of the features. Final classification is then done by majority vote, to remove overfitting\n",
    "noise and make the model extremely robust.\n",
    "There's one interesting addendum to this: in a random forest decision tree, making a split is only\n",
    "done with a subset of the features available at every step. This way, strong predictors don't\n",
    "dominate every tree they appear in and overly couple the trees.\n",
    "Team: Jocelyn, Kevin, Nicholas\n",
    "Author: Nicholas\n",
    "\"\"\"\n",
    "\n",
    "from itertools import combinations\n",
    "from random import sample\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    \"\"\"A random forest classifier.\"\"\"\n",
    "    def __init__(self, n, b, n_ratio=True, b_ratio=True):\n",
    "        \"\"\"Initializes a bare random forest classifier. N is the number of elements to bootstrap from the\n",
    "        training data, or a ratio of the total data size if n_ratio is True. B is the number of\n",
    "        trees to use when classifying. If b_ratio is True, b will instead be a ratio of the total\n",
    "        data input dimensionality.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.n_ratio = n_ratio\n",
    "        self.b_ratio = b_ratio\n",
    "        self.b = b\n",
    "        self.trees = []\n",
    "\n",
    "    @classmethod\n",
    "    def get_all_subsets(self, items):\n",
    "        \"\"\"Returns a list of every subset of the given input.\"\"\"\n",
    "        subsets = []\n",
    "        for i in range(1, len(items)+1):\n",
    "            subsets += [combo for combo in combinations(items, i)]\n",
    "        return subsets\n",
    "\n",
    "    @classmethod\n",
    "    def get_random_samples(cls, choices, n):\n",
    "        \"\"\"Draws n different subsets of choices and returns them as a list.\"\"\"\n",
    "        return sample(cls.get_all_subsets(choices), n)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fits a random forest classifier on X mapping to Y, a vector with the same height but\n",
    "        classes instead of predictors.\"\"\"\n",
    "        \n",
    "        # get correct number of trees\n",
    "        tree_num = self.b if not self.b_ratio else int(self.b * X.shape[1])\n",
    "\n",
    "        # get the right number of samples of features\n",
    "        feature_samples = self.get_random_samples(X.columns, tree_num)\n",
    "        # get the right number of samples of data\n",
    "        bootstrap_size = self.n if not self.n_ratio else int(self.n * X.shape[0])\n",
    "        bootstraps = [sample(range(X.shape[0]), bootstrap_size) for i in range(tree_num)]\n",
    "\n",
    "        data_subsets = [(X.loc[bootstraps[i], feature_samples[i]], y.loc[bootstraps[i], :])\n",
    "                        for i in range(tree_num)]\n",
    "        self.trees = [RandomDecisionTree() for i in range(tree_num)]\n",
    "        for i in range(tree_num):\n",
    "            self.trees[i].fit(*data_subsets[i])  # fit that particular one\n",
    "\n",
    "    def predict(self, X_new):\n",
    "        \"\"\"Uses majority voting with a random forest to predict y.\"\"\"\n",
    "        votes = [tree.predict(X_new) for tree in self.trees]  # get predictions\n",
    "        return max(votes, key=lambda x: votes.count(x))  # get most common and return it\n",
    "\n",
    "\n",
    "\n",
    "mat = [[\"human\", \"warm-blooded\", \"yes\", \"no\", \"no\", \"yes\"],\n",
    "       [\"pigeon\", \"warm-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "       [\"elephant\", \"warm-blooded\", \"yes\", \"yes\", \"no\", \"yes\"],\n",
    "       [\"leopard shark\", \"cold-blooded\", \"yes\", \"no\", \"no\", \"no\"],\n",
    "       [\"turtle\", \"cold-blooded\", \"no\", \"yes\", \"no\", \"no\"],\n",
    "       [\"penguin\", \"cold-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "       [\"eel\", \"cold-blooded\", \"no\", \"no\", \"no\", \"no\"],\n",
    "       [\"dolphin\", \"warm-blooded\", \"yes\", \"no\", \"no\", \"yes\"],\n",
    "       [\"spiny anteater\", \"warm-blooded\", \"no\", \"yes\", \"yes\", \"yes\"],\n",
    "       [\"gila monster\", \"cold-blooded\", \"no\", \"yes\", \"yes\", \"no\"]]\n",
    "\n",
    "df = pd.DataFrame(mat, columns=[\"Name\",\n",
    "                                \"Body Temperature\",\n",
    "                                \"Gives Birth\",\n",
    "                                \"Four-legged\",\n",
    "                                \"Hibernates\",\n",
    "                                \"Class Label\"])\n",
    "\n",
    "\n",
    "X = df.loc[:, [\"Body Temperature\", \"Gives Birth\", \"Four-legged\", \"Hibernates\"]]\n",
    "y[\"Class Label\"] = pd.DataFrame(y[\"Class Label\"].apply(lambda x: 1 if x == \"yes\" else 0))\n",
    "y = df.loc[:, [\"Class Label\"]]\n",
    "\n",
    "X[\"Body Temperature\"] = X[\"Body Temperature\"].apply(lambda x: 1 if x == \"warm-blooded\" else 0)\n",
    "for col in X.columns[1:]:\n",
    "    X[col] = X[col].apply(lambda x: 1 if x == \"yes\" else 0)\n",
    "\n",
    "X_training = X.loc[:7, :]\n",
    "X_test = X.loc[7:, :]\n",
    "\n",
    "y_training = y.loc[:7, [\"Class Label\"]]\n",
    "y_test = y.loc[7:, [\"Class Label\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(1, 1)\n",
    "rf.fit(X_training.values, y_training.values)\n",
    "print(rf.predict(X_test))\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
